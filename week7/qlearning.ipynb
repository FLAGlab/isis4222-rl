{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "352e05fd-bdce-4361-8510-31d062d3f8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def __init__(self):\n",
    "        self.board = [False for x in range(0, 5)]\n",
    "        self.board[4] = True\n",
    "    \n",
    "    def start(self):\n",
    "        return 0\n",
    "    \n",
    "    def end(self): \n",
    "        return len(self.board)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0aa88d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "class Learner:\n",
    "    def __init__(self, agent, env, alpha=0.1, gamma=0.6, epsilon=0.1):\n",
    "        #hyper parameters\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.environment = env\n",
    "        self.agent = agent          #actual agent\n",
    "        self.qtable = self.__initdic__() #rewards table\n",
    "    \n",
    "    def __initdic__(self):\n",
    "        table = dict()\n",
    "        for i in range(0, self.environment.end()):\n",
    "            table[i] = np.zeros(len(self.agent.actions))\n",
    "        return table\n",
    "\n",
    "    def run(self):\n",
    "        done = False\n",
    "        while not done:\n",
    "            current_state = self.agent.state\n",
    "            if random.uniform(0,1) < self.epsilon:\n",
    "                action = self.randomAction()\n",
    "            else:\n",
    "                action = np.argmax(self.qtable[current_state]) \n",
    "            next_state, reward, done, info = self.step(action)\n",
    "            old_value = self.qtable[current_state][action]\n",
    "            next_max = np.max(self.qtable[next_state])\n",
    "            new_value = (1 - self.alpha)*old_value + self.alpha*(reward + self.gamma*next_max)\n",
    "            self.qtable[current_state][action] = new_value\n",
    "\n",
    "            print(info)\n",
    "            print(f'{current_state}, {action}, {next_state}')\n",
    "\n",
    "    def randomAction(self):\n",
    "        return random.randint(0,len(self.agent.actions)-1)\n",
    "\n",
    "    def step(self, action):\n",
    "        old_state = self.agent.state\n",
    "        reward, done = self.getRewards(old_state, self.agent.getAction(action))\n",
    "        self.agent.action(action)\n",
    "        next_state = self.agent.state\n",
    "        info = f'Executed action: {self.agent.getAction(action)} at state {old_state}'\n",
    "        return next_state, reward, done, info\n",
    "\n",
    "    def getRewards(self, state, action):\n",
    "        if state == self.environment.end() - 2 and action == 'right':\n",
    "            return 10, True\n",
    "        else:\n",
    "            return 0, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6ca87dd-4171-4fb0-9e9b-6b5b393d958b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, rb):\n",
    "        self.state = 0\n",
    "        self.actions = [0,1]\n",
    "        self.rightBound = rb - 1\n",
    "\n",
    "    def forward(self):\n",
    "        self.state = min(self.state + 1, self.rightBound)\n",
    "        \n",
    "    def back(self):\n",
    "        self.state = max(self.state - 1, 0)\n",
    "        \n",
    "    def action(self, action : int):\n",
    "        if action:\n",
    "            self.forward()\n",
    "        else:\n",
    "            self.back()\n",
    "    \n",
    "    def getAction(self, action : int):\n",
    "        if action:\n",
    "            return 'right'\n",
    "        else:\n",
    "            return 'left'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21efb772-8d63-4e22-9ca1-b1967a2889fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    episodes = 10\n",
    "    e = Environment()\n",
    "    a = Agent(e.end())\n",
    "    l = Learner(a, e)\n",
    "    for i in range(0, episodes):\n",
    "        print(f\"Episode: {i+1}\")\n",
    "        l.run()\n",
    "        a.reset()\n",
    "    print(l.qtable)\n",
    "        \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b9b386-91c3-4008-ae53-940199751ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
